### *关于 ChatGPT*

#### 1、应用  

ChatGPT + 金融，可以为客户提供智能化的 **投资建议和风险管理方案**  
ChatGPT + 医疗，可以 **辅助** 医生进行 **疾病诊断和药物研发**  
ChatGPT + 零售领域，可以为消费者提供 **个性化的购物建议和客户服务**  
ChatGPT + 搜索引擎  
ChatGPT + 智慧办公  
ChatGPT + 教育  
ChatGPT + 游戏（策划、内容、制作、美工）  
ChatGPT + 音乐  
ChatGPT + 广告营销  
ChatGPT + 设计  
ChatGPT + 影视  
GPT4 可以做到视频剪辑、新闻播报  

微软公司一直和 ChatGPT 的母公司 OpenAI 保持合作，他们将 ChatGPT 整合进自己的 bing 搜索引擎里面；谷歌推出类 ChatGPT 的 Bard；百度文心一言......  

#### 2、模型基础

- LM  
    Language Model，语言模型，这是ChatGPT的基石的基石  
    通过已经有的词预测接下来的词  
    Greedy Search（中文叫贪心搜索），Beam Search（中文叫集束搜索）  
    简单模型就是把一句话切成一个个词，然后统计概率，这类模型叫做 N-gram 语言模型，是最简单的语言模型，这里的N表示每次用到的上下文长度  
    实际中我们往往不叫一个词为「词」，而是「Token」，你可以将其理解为一小块，可以是一个字，也可以是两个字的词，或三个字的词，取决于你怎么 Token 化  

- Transformer  
    包含 Encode、Decode、Multi-Head 多头自注意力机制  
    关注 Encoder 中 Token 的信息的机制就是 Attention（注意力机制）  
    Encode 是知道数据的，所以建模时可以同时利用当前的 **历史 Token 和未来（前面的）Token**；但 Decode 时，因为是一个 Token 一个 Token 输出来的，所以只能根据历史 Token 以及 Encoder 的 Token 表示进行建模，而 **不能利用未来的 Token**  
    Multi-Head 简单来说，就是把上面这种自注意机制重复 Multi 次（Multi 个 Head），每个注意到的信息不一样，这样就可以捕获到更多信息  

- GPT  
    生成式预训练 Transformer  
    从 GPT-1、GPT-2、GPT-3、GPT-3.5（ChatGPT）一直到现在的 GPT-4  
    模型参数不断扩大  
    预训练就是在大量语料上进行预先的训练  

    > Zero-Shot：直接给模型任务输入让它输出任务结果  
    Few-Shot：给模型提供一些示例，然后再给出任务，让它给出输出结果  

- RLHF  
    Reinforcement Learning from Human Feedback，从人类反馈中学习。有此利刃，ChatGPT 才是那个 ChatGPT，不然就只能是 GPT-3  

#### 3、展望

如今各大公司纷纷推出自己动辄便数千亿级参数量的模型，所用数据更是无法统计，尽管语言模型并非监督训练，但 **数据过滤，人工反馈** 等阶段还是需要高昂的人力成本；这样超大模型加海量数据的组合，每次训练都需要耗费 **数百万美元**，用 **数千台 GPU** 来完成，即使后续更新时并不需要从头训练，但花费依旧不菲，并不是一个可持续性的策略，没点财力的公司，是根本养不起的

当前对话模型更多关注在开放域场景，合理的回复往往不唯一，这意味着在训练阶段很难制作标签，同时在推理时模型也比较容易“放飞自我”，生成千奇百怪的回复结果，其中难免调用一些错误的知识。针对这种“一对多”的场景，很多研究致力于探索对话模型的 **可控生成**，通过添加一些控制因素，使生成文本满足一定的约束。**提示学习（Prompt Learning）**本身就是一种 **在输入上加入可控因素** 从而引导正确的生成，这已经成了最新流行的范式；另外在解码阶段，也可以适当调整策略 **对生成的多条候选回复结果重新排序**，尽可能选择出 **包含目标词汇** 的回复结果，控制生成内容

此前研究表明，文本的语言学知识多存储在 **模型的低层网络**，所以在微调更新时可以 **冻结中低层的模型参数**，从而加速学习 

#### 参考资料

https://github.com/datawhalechina/hugging-llm/blob/main/content/


### *吴恩达和 openai 的 prompt 课程*

#### 1、模板

``` python
import os
import openai
openai.api_key = os.getenv('OPENAI_API_KEY')

def get_completion(prompt, model='gpt-3.5-turbo'):
    messages = [
        {'role': 'user',
        'content': prompt},
    ]
    response = openai.ChatCompletion.create(
        model = model,
        messages = messages,
        temperature = 0,
    )
    return response.choices[0].message['content']

def get_completion_from_messages(messages, model='gpt-3.5-turbo', temperature=0):
    response = openai.ChatCompletion.create(
        model = model,
        messages = messages,
        temperature = temperature,
    )
    return response.choices[0].message['content']
```

#### 2、指南

- RLHF  
    Reinforcement Learning from Human Feedback，从人类反馈中学习  

- 提示词书写规范  
    用一些特定符号隔开，让模型知道需要处理的文本是哪部分，例如：  
    
        """ 文本 """
        ``` 文本 ```
        --- 文本 ---
        < 文本 >
        <tag> 文本 </tag>

- 指定输出格式  
    让 ChatGPT 用 JSON 或者 HTML 等格式输出，也可以自定义输出格式例如 1) 2) 3)  
    
    > `from IPython.display import display, HTML`  
    可以在 jupyter 中展示 HTML  

- 给定少量的训练提示  
    在 prompt 中给定一个或多个 **示例及回答**，让 ChatGPT 模仿  

- 多任务情况  
    分点列出 step，指定每一步要完成的内容  

- 评判对错  
    在让 ChatGPT 判断某个事物对错之前，先让它自己进行逻辑推断得到结论，再通过对比判断对错  

- 对于生成虚假的内容  
    为了减少 Hallucinations 幻觉，先让 ChatGPT 找到比较可靠的相关信息，再引用进行回答  

#### 3、迭代

不断改进提示词  
想法 → 实现 → 获得实验结果 → 误差分析 → 新的想法 → 实现 →...  

- 优化 prompt 的步骤  
    清晰明确地写出 prompt  
    分析为什么没能得到想要的输出  
    改进想法和 prompt  
    重复上述过程  

#### 4、摘要

将 ChatGPT 用于长评论的总结  
可以控制 ChatGPT 回复的句子长度：通过限制句子个数、字数等等  
修改 prompt 使其适用于特定的业务、情景  

#### 5、推理

ChatGPT 可用于评论情感分析；商品评价；对新闻报刊的主题提取  

- 零样本学习  
    没有提供带标签的训练样本，包括  
    Zero-Shot：直接给模型任务输入让它输出任务结果  
    Few-Shot：给模型提供一些示例，然后再给出任务，让它给出输出结果  

#### 6、转换

ChatGPT 用于文本翻译  

- 文本格式转换  
    正式或者非正式场合  
    字典转 JSON 或者 HTML 等等  

- 语气转换  
    例如给同事或者教授写邮件时，需要注意书写的语气  

- 拼写、语法检查  

> `from redlines import Redlines`  
该库可以用于检查文本之间的差异  

#### 7、扩展

ChatGPT 用于文本扩写，例如可以生成个性化电子邮件  
参数 `temperature` 控制回答的随机性、多样性，越大越多样  

#### 8、聊天机器人

``` python
message = [
    {"role": "system",
    "content": "。。。"},
    
    {"role": "user",
    "content": "。。。"},
    
    {"role": "assistant",
    "content": "。。。"},
    
    ...
]
```

system 作为高层指令，起到引导作用，设置 assistant 的行为，打造属于自己的聊天机器人  
要使得模型提取或者记住信息，需要用到上下文 context， 在 message 中提供或者存储在，message 列表中  

> `import panel as pn`  
可以生成 GUI 界面  


### *神经网络*

在达到相同感受野的情况下，卷积核越小，所需要的参数和计算量越小  

卷积核大小必须大于1才有提升感受野的作用，1排除了  
而大小为偶数的卷积核即使对称地加padding也不能保证输入feature map尺寸和输出feature map尺寸不变（画个图算一下就可以发现），2排除了  
所以一般都用3作为卷积核大小  

每一层卷积有多少channel数，以及一共有多少层卷积，这些暂时没有理论支撑，一般都是靠感觉去设置几组候选值，然后通过实验挑选出其中的最佳值  

#### 注意事项

1、刚开始, 直接奔着过拟合去. 没错, 就是训练过拟合网络  

2、Loss设计要合理.  
一般来说分类就是Softmax, 回归就是L2的loss. 但是要注意loss的错误范围(主要是回归)  

3、观察loss胜于观察准确率  
准确率虽然是评测指标, 但是训练过程中还是要注意loss的. 你会发现有些情况下, 准确率是突变的, 原来一直是0, 可能保持上千迭代, 然后突然变1. 要是因为这个你提前中断训练了, 只有老天替你惋惜了. 而loss是不会有这么诡异的情况发生的, 毕竟优化目标是loss.  

4、确认分类网络学习充分  
分类网络就是学习类别之间的界限. 你会发现, 网络就是慢慢的从类别模糊到类别清晰的. 怎么发现? 看Softmax输出的概率的分布. 如果是二分类, 你会发现, 刚开始的网络预测都是在0.5上下, 很模糊. 随着学习过程, 网络预测会慢慢的移动到0,1这种极值附近. 所以, 如果你的网络预测分布靠中间, 再学习学习.  

5、Learning Rate设置合理  

6、对比训练集和验证集的loss  

7、清楚receptive field的大小  

#### 其他问题

预处理，mean/std zero-center就够了, PCA, 白化什么的都用不上. 我个人观点, 反正CNN能学习encoder, PCA用不用其实关系不大  

数据集记得打乱，shuffle, shuffle, shuffle.  

网络原理的理解最重要, CNN的conv这块, 你得明白sobel算子的边界检测.  

Dropout, Dropout, Dropout(不仅仅可以防止过拟合, 其实这相当于做人力成本最低的Ensemble, 当然, 训练起来会比没有Dropout的要慢一点, 同时网络参数你最好相应加一点, 对, 这会再慢一点).  

CNN更加适合训练回答是否的问题, 如果任务比较复杂, 考虑先用分类任务训练一个模型再finetune.  

无脑用ReLU(CV领域).  

无脑用3x3.  

无脑用xavier.  

LRN一类的, 其实可以不用. 不行可以再拿来试试看.  

filter数量2^n.  

多尺度的图片输入(或者网络内部利用多尺度下的结果)有很好的提升效果.  

第一层的filter, 数量不要太少. 否则根本学不出来(底层特征很重要).  

sgd adam 这些选择上, 看你个人选择. 一般对网络不是决定性的. 反正我无脑用sgd + momentum.  

batch normalization我一直没用, 虽然我知道这个很好, 我不用仅仅是因为我懒. 所以要鼓励使用batch normalization.  

不要完全相信论文里面的东西. 结构什么的觉得可能有效果, 可以拿去试试.  

你有95%概率不会使用超过40层的模型.  

shortcut的联接是有作用的.  

暴力调参最可取, 毕竟, 自己的生命最重要. 你调完这个模型说不定过两天这模型就扔掉了.  

Google的inception论文, 结构要好好看看.  

一些传统的方法, 要稍微了解了解. 我自己的程序就用过1x14的手写filter, 写过之后你看看inception里面的1x7, 7x1 就会会心一笑...  

#### 参考资料

[卷积神经网络的卷积核大小、个数，卷积层数如何确定呢？](https://datayx.blog.csdn.net/article/details/103052695)

